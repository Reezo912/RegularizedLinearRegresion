{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importo  todos mis datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path donde se encuentran mis archivos train\n",
    "BASE_PATH = \"../data/processed\"\n",
    "TRAIN_PATHS = [\n",
    "    \"X_train_con_outliers_raw.xlsx\",\n",
    "    \"X_train_sin_outliers_raw.xlsx\",\n",
    "    \"X_train_con_outliers_norm.xlsx\",\n",
    "    \"X_train_sin_outliers_norm.xlsx\",\n",
    "    \"X_train_con_outliers_scal.xlsx\",\n",
    "    \"X_train_sin_outliers_scal.xlsx\"\n",
    "]\n",
    "\n",
    "# Guardo cada uno de estos archivos dentro de una lista\n",
    "TRAIN_DATASETS = []\n",
    "for path in TRAIN_PATHS:\n",
    "    TRAIN_DATASETS.append(\n",
    "        # pd.read_excel(BASE_PATH + \"/\" + path)\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "        # pd.read_excel(os.path.join(BASE_PATH, path))\n",
    "    )\n",
    "\n",
    "# Path donde se encuentran mis archivos test\n",
    "TEST_PATHS = [\n",
    "    \"X_test_con_outliers_raw.xlsx\",\n",
    "    \"X_test_sin_outliers_raw.xlsx\",\n",
    "    \"X_test_con_outliers_norm.xlsx\",\n",
    "    \"X_test_sin_outliers_norm.xlsx\",\n",
    "    \"X_test_con_outliers_scal.xlsx\",\n",
    "    \"X_test_sin_outliers_scal.xlsx\"\n",
    "]\n",
    "\n",
    "# Guardo cada uno de estos archivos dentro de una lista\n",
    "TEST_DATASETS = []\n",
    "for path in TEST_PATHS:\n",
    "    TEST_DATASETS.append(\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "    )\n",
    "\n",
    "y_train = pd.read_excel(f\"{BASE_PATH}/y_train.xlsx\")\n",
    "y_test = pd.read_excel(f\"{BASE_PATH}/y_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entreno un modelo por cada uno de mis datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_rmse  test_rmse  train_r2   test_r2\n",
      "0    1.492746   1.582346  0.945233  0.938412\n",
      "1    1.519230   1.598188  0.943273  0.937173\n",
      "2    1.492443   1.582023  0.945256  0.938437\n",
      "3    1.519230   1.598188  0.943273  0.937173\n",
      "4    1.492443   1.582023  0.945256  0.938437\n",
      "5    1.519230   1.598188  0.943273  0.937173\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, dataset in enumerate(TRAIN_DATASETS):\n",
    "    model = LinearRegression(n_jobs = 14)\n",
    "    model.fit(dataset, y_train)\n",
    "    y_pred_train = model.predict(dataset)\n",
    "    y_pred_test = model.predict(TEST_DATASETS[index])\n",
    "\n",
    "    results.append({\n",
    "        \"train_r2\": r2_score(y_train, y_pred_train),\n",
    "        \"train_mse\": mean_squared_error(y_train, y_pred_train),\n",
    "        \"test_r2\": r2_score(y_test, y_pred_test),\n",
    "        \"test_mse\": mean_squared_error(y_test, y_pred_test),\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "# Calcular RMSE\n",
    "df_results[\"train_rmse\"] = np.sqrt(df_results[\"train_mse\"])\n",
    "df_results[\"test_rmse\"] = np.sqrt(df_results[\"test_mse\"])\n",
    "# Seleccionar columnas relevantes para mostrar en tabla\n",
    "df_results = df_results[[\"train_rmse\", \"test_rmse\", \"train_r2\", \"test_r2\"]]\n",
    "# Mostrar tabla\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": np.linspace(0.0001, 1000, 100),\n",
    "    \"max_iter\": [100, 300, 600, 1000, 2000, 4000, 8000, 12000],\n",
    "    \"tol\": np.linspace(0.0001, 0.01, 100),\n",
    "}\n",
    "\n",
    "\n",
    "param_grid_elastic = {\n",
    "    \"alpha\": np.linspace(0.0001, 1000, 100),\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.9],\n",
    "    \"max_iter\": [100, 300, 1000, 2000, 4000, 8000, 12000],\n",
    "    \"tol\": np.linspace(0.0001, 0.01, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplico optimizacion RIDGE sobre mi mejor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_r2  train_mse   test_r2  test_mse\n",
      "0  0.945232   2.228356  0.938413   2.50378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Indice de mi mejor dataset\n",
    "best_dataset = 4\n",
    "\n",
    "ridge_model = Ridge(random_state= 42)\n",
    "\n",
    "grid_ridge = GridSearchCV(estimator = ridge_model, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = 14)\n",
    "\n",
    "grid_ridge.fit(TRAIN_DATASETS[best_dataset], y_train)\n",
    "\n",
    "y_pred_train = grid_ridge.predict(TRAIN_DATASETS[best_dataset])\n",
    "y_pred_test = grid_ridge.predict(TEST_DATASETS[best_dataset])\n",
    "\n",
    "\n",
    "results_ridge = []\n",
    "\n",
    "results_ridge.append({\n",
    "        \"train_r2\": r2_score(y_train, y_pred_train),\n",
    "        \"train_mse\": mean_squared_error(y_train, y_pred_train),\n",
    "        \"test_r2\": r2_score(y_test, y_pred_test),\n",
    "        \"test_mse\": mean_squared_error(y_test, y_pred_test),\n",
    "    })\n",
    "\n",
    "df_ridge = pd.DataFrame(results_ridge)\n",
    "\n",
    "print(df_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplico optimizacion LASSO sobre mi mejor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_r2  train_mse  test_r2  test_mse\n",
      "0    0.9452   2.229655  0.93854  2.498639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Carga de los datos de train y test\n",
    "# Estos datos deben haber sido normalizados y correctamente tratados en un EDA completo\n",
    "\n",
    "lasso_model = Lasso(random_state=42)\n",
    "\n",
    "grid_lasso = GridSearchCV(estimator = lasso_model, param_grid = param_grid, scoring = 'r2', cv = 5, n_jobs = 14)\n",
    "\n",
    "\n",
    "grid_lasso.fit(TRAIN_DATASETS[best_dataset], y_train)\n",
    "\n",
    "y_pred_train = grid_lasso.predict(TRAIN_DATASETS[best_dataset])\n",
    "y_pred_test = grid_lasso.predict(TEST_DATASETS[best_dataset])\n",
    "\n",
    "\n",
    "results_lasso = []\n",
    "\n",
    "results_lasso.append({\n",
    "        \"train_r2\": r2_score(y_train, y_pred_train),\n",
    "        \"train_mse\": mean_squared_error(y_train, y_pred_train),\n",
    "        \"test_r2\": r2_score(y_test, y_pred_test),\n",
    "        \"test_mse\": mean_squared_error(y_test, y_pred_test),\n",
    "    })\n",
    "\n",
    "df_lasso = pd.DataFrame(results_lasso)\n",
    "\n",
    "print(df_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplico optimizacion Elastic Net sobre mi mejor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_r2  train_mse   test_r2  test_mse\n",
      "0  0.945153   2.231577  0.938752  2.490002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+01, tolerance: 1.022e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net_model = ElasticNet(random_state=42)\n",
    "\n",
    "grid_elastic = GridSearchCV(estimator = elastic_net_model, param_grid = param_grid_elastic, scoring = 'r2', cv = 5, n_jobs = 14)\n",
    "\n",
    "grid_elastic.fit(TRAIN_DATASETS[best_dataset], y_train)\n",
    "\n",
    "y_pred_train = grid_elastic.predict(TRAIN_DATASETS[best_dataset])\n",
    "y_pred_test = grid_elastic.predict(TEST_DATASETS[best_dataset])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_elastic = []\n",
    "\n",
    "results_elastic.append({\n",
    "        \"train_r2\": r2_score(y_train, y_pred_train),\n",
    "        \"train_mse\": mean_squared_error(y_train, y_pred_train),\n",
    "        \"test_r2\": r2_score(y_test, y_pred_test),\n",
    "        \"test_mse\": mean_squared_error(y_test, y_pred_test),\n",
    "    })\n",
    "\n",
    "df_elastic = pd.DataFrame(results_elastic)\n",
    "\n",
    "print(df_elastic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
